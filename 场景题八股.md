# 场景题八股

------

## 40亿个QQ号，如何用1GB内存处理（去重）？

> 1、BitMap
>
> 2、布隆过滤器

参考链接：[腾讯三面：40亿个QQ号，如何用1GB内存处理？](https://mp.weixin.qq.com/s/gv3pfYs44pjbLLHlDOsIYw)



## 给你一个数字如何知道其是否在 10 亿不重复数字中

对于这种大数据量去重/判重的场景，我们可以考虑使用 **位图（Bitmap）**。位图可以在不占用太多内存的前提下，解决海量数据的存在性问题，进而实现去重/判重。

**什么是 Bitmap？** Bitmap 是一种用于存储二进制数据的数据结构。简单来说，Bitmap 就是使用二进制位来表示某个元素是否存在的数组。每一位只有两种状态，可以方便地用 0 和 1 来表示存在与不存在。

> 位数组

![图片](https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9Tzn7r8GS5iab8bB4fm5ic1roetprAvrCeTIgMe5TI0FCe8459Y9GdcDWqWl4MO8W1TQUCHRg58ccQzA/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

使用 Bitmap 的话，一个数字只需要占用 1 个 bit。

我们假设数字为 QQ 号。QQ 号是 4 字节无符号整数，共 32bit, 也就是说，QQ 号的取值范围是：[0, 2^32 - 1]。2^32 - 1 的值是 4294967295, 是一个 10 位的整数，大约是 43 亿。

这样的话，大约需要 512MB 内存就可以表示所有的 QQ 号了，计算过程：4294967295 / 8 / 1024 / 1024 ≈ 512MB。

假设我们要把 QQ 号 1384593330 放入 Bitmap，我们只需要将 1384593330 位置的数组元素设置为 1 即可。当我们要判断对应的 QQ 号是否已经存在于 Bitmap 中时，只需要查看对应位置的数组元素是否为 1 即可。

> Bloom Filter 的简单原理示意图

![图片](https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9Tzn7r8GS5iab8bB4fm5ic1roe5C2vZGycnicwGLAv3icCdAShf6HbBfiaWcH24x8rGmZJuLpRV2ykaibu0A/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

下面是使用 Bitmap 命令完成 QQ 号判重的简单演示：

```
> SETBIT mykey 1384593330 1
0
> GETBIT mykey 1384593330
1
> SETBIT mykey 1384593331 1
0
> GETBIT mykey 1384593331
```

如果我们想要进一步节省空间，并且容许较小的误差的话，还可以使用 **布隆过滤器（Bloom Filter）** 进一步优化。布隆过滤器就是基于 Bitmap 实现的，只是多加了哈希函数映射这一步。



## 1G 大小的文件中出现频率最高的 100 个词

这个问题可以通过多路归并排序方法解决。

**步骤 1：多路归并排序对大文件进行排序**

多路归并排序对大文件排序的步骤如下：

1. 将 1GB 的文件按顺序切分成多个小文件，每个文件大小不超过 2MB，总共 500 个小文件。这样可以确保每个小文件在后续处理时能够被完全加载到内存中，满足 10MB 的内存限制。
2. 使用 10MB 的内存分别对每个小文件中的单词进行排序。这样可以确保每个小文件内部是有序的，这为后续的多路归并排序打下基础。
3. 使用一个大小为 500 的最小堆，将所有 500 个已排序的小文件进行合并，生成一个完全有序的文件。

其中第 3 步，对 500 个小文件进行多路排序的思路如下：

1. 初始化一个最小堆，大小就是有序小文件的个数 500。堆中的每个节点存放每个有序小文件对应的输入流。
2. 按照每个有序文件中的下一行数据对所有文件输入流进行排序，单词小的输入文件流放在堆顶。
3. 拿出堆顶的输入流，并且将下一行数据写入到最终排序的文件中，如果拿出来的输入流还有数据的话，那么就将这个输入流再次添加到栈中。否则说明该文件输入流中没有数据了，那么可以关闭这个流。
4. 循环这个过程，直到所有文件输入流中没有数据为止。

**步骤 2：统计出现频率最高的 100 个词**

1. 初始化一个 100 个节点的小顶堆，用于保存 100 个出现频率最高的单词。
2. 遍历整个文件，一个单词一个单词地从文件中读取出来，并且进行计数。
3. 等到遍历的单词和上一个单词不同的话，那么上一个单词及其频率如果大于堆顶的词的频率，那么放在堆中。否则不放

归并排序涉及大量的磁盘读写操作，可能会成为性能瓶颈。下面是一些优化建议：

- 缓冲区大小：合理设置缓冲区大小，减少磁盘 I/O 次数。
- 使用更高效的存储介质：如 SSD 以提高读写速度。
- 并行归并：在硬件支持的情况下，进行多线程或多进程的并行归并，提升整体速度。



